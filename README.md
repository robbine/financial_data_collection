# Financial Data Collector

ä¸€ä¸ªæ¨¡å—åŒ–çš„é‡‘èæ•°æ®é‡‡é›†ã€å¤„ç†å’Œå­˜å‚¨ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ•°æ®æºå’Œå®æ—¶å¤„ç†ã€‚

## ç‰¹æ€§

### ğŸ—ï¸ æ¨¡å—åŒ–æ¶æ„
- **ä¾èµ–æ³¨å…¥ç³»ç»Ÿ**: æ¾è€¦åˆçš„æ¨¡å—ä¾èµ–ç®¡ç†
- **äº‹ä»¶é©±åŠ¨æ¶æ„**: å¼‚æ­¥äº‹ä»¶å¤„ç†å’Œé€šä¿¡
- **æ’ä»¶ç³»ç»Ÿ**: åŠ¨æ€åŠ è½½å’Œå¸è½½åŠŸèƒ½æ¨¡å—
- **ä¸­é—´ä»¶ç®¡é“**: æ•°æ®å¤„ç†é“¾å¼æ“ä½œ
- **æ¨¡å—ç”Ÿå‘½å‘¨æœŸç®¡ç†**: ç»Ÿä¸€çš„å¯åŠ¨ã€åœæ­¢ã€é‡å¯æœºåˆ¶

### ğŸ“Š æ•°æ®é‡‡é›†
- **Webçˆ¬è™«**: åŸºäºCrawl4AIçš„é«˜çº§ç½‘é¡µçˆ¬å–ï¼Œæ”¯æŒLLMæ™ºèƒ½æå–
- **APIæ•°æ®æº**: RESTful APIæ•°æ®è·å–ï¼Œæ”¯æŒå¤šç§é‡‘èAPI
- **æ•°æ®åº“è¿æ¥**: ç›´æ¥æ•°æ®åº“æŸ¥è¯¢ï¼Œæ”¯æŒå¤šç§æ•°æ®åº“ç±»å‹
- **æ–‡ä»¶å¤„ç†**: å¤šç§æ ¼å¼æ–‡ä»¶è¯»å–å’Œå¤„ç†

### ğŸ”„ æ•°æ®å¤„ç†
- **æ•°æ®æ¸…æ´—**: å»é‡ã€å¡«å……ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼å¤„ç†
- **AIå¤„ç†**: æ™ºèƒ½æ•°æ®åˆ†æå’Œå¤„ç†
- **PITè½¬æ¢**: ç‚¹å¯¹ç‚¹æ•°æ®è½¬æ¢
- **å®æ—¶å¤„ç†**: æµå¼æ•°æ®å¤„ç†

### ğŸ“ˆ ä»»åŠ¡è°ƒåº¦
- **å®šæ—¶ä»»åŠ¡**: åŸºäºcronè¡¨è¾¾å¼çš„ä»»åŠ¡è°ƒåº¦
- **ä»»åŠ¡ç®¡ç†**: ä»»åŠ¡çŠ¶æ€è·Ÿè¸ªå’Œé‡è¯•æœºåˆ¶
- **å¹¶å‘æ§åˆ¶**: å¤šä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ

### ğŸ’¾ å­˜å‚¨ç®¡ç†
- **æ•°æ®åº“å­˜å‚¨**: å…³ç³»å‹æ•°æ®åº“æ”¯æŒ
- **ç¼“å­˜ç³»ç»Ÿ**: é«˜æ€§èƒ½ç¼“å­˜å­˜å‚¨
- **PITå­˜å‚¨**: ä¸“ç”¨æ•°æ®æ ¼å¼å­˜å‚¨

### ğŸ” ç›‘æ§å’Œå¥åº·æ£€æŸ¥
- **å®æ—¶ç›‘æ§**: ç³»ç»ŸçŠ¶æ€å®æ—¶ç›‘æ§
- **å¥åº·æ£€æŸ¥**: æ¨¡å—å¥åº·çŠ¶æ€æ£€æŸ¥
- **å‘Šè­¦ç³»ç»Ÿ**: å¼‚å¸¸æƒ…å†µè‡ªåŠ¨å‘Šè­¦

## æ¶æ„è®¾è®¡

### æ ¸å¿ƒæ¨¡å—

```
src/financial_data_collector/
â”œâ”€â”€ core/                    # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ config/              # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ crawler/             # æ•°æ®é‡‡é›†
â”‚   â”œâ”€â”€ processor/           # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ scheduler/           # ä»»åŠ¡è°ƒåº¦
â”‚   â”œâ”€â”€ storage/             # å­˜å‚¨ç®¡ç†
â”‚   â”œâ”€â”€ di/                  # ä¾èµ–æ³¨å…¥
â”‚   â”œâ”€â”€ events/              # äº‹ä»¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ middleware/          # ä¸­é—´ä»¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ plugins/             # æ’ä»¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ module_manager.py   # æ¨¡å—ç®¡ç†å™¨
â”‚   â”œâ”€â”€ health_checker.py    # å¥åº·æ£€æŸ¥
â”‚   â””â”€â”€ interfaces.py        # æ¥å£å®šä¹‰
â”œâ”€â”€ api/                     # APIæ¨¡å—
â”œâ”€â”€ models/                   # æ•°æ®æ¨¡å‹
â”œâ”€â”€ utils/                    # å·¥å…·å‡½æ•°
â””â”€â”€ web/                      # Webç•Œé¢
```

### æ¨¡å—åŒ–ç‰¹æ€§

#### 1. ä¾èµ–æ³¨å…¥å®¹å™¨
```python
from src.financial_data_collector.core.di import DIContainer

container = DIContainer()
container.register_singleton(ConfigManager, ConfigManager)
container.register_factory(DataProcessor, lambda: DataProcessor())

# è‡ªåŠ¨è§£æä¾èµ–
processor = container.get(DataProcessor)
```

#### 2. äº‹ä»¶ç³»ç»Ÿ
```python
from src.financial_data_collector.core.events import EventBus, DataCollectedEvent

event_bus = EventBus()

# è®¢é˜…äº‹ä»¶
def handle_data_collected(event):
    print(f"Data collected: {event.data}")

event_bus.subscribe("data_collected", handle_data_collected)

# å‘å¸ƒäº‹ä»¶
event = DataCollectedEvent(data={"test": "data"}, source="crawler")
event_bus.publish(event)
```

#### 3. ä¸­é—´ä»¶ç³»ç»Ÿ
```python
from src.financial_data_collector.core.middleware import (
    MiddlewarePipeline, LoggingMiddleware, ValidationMiddleware
)

pipeline = MiddlewarePipeline("DataProcessing")
pipeline.add_middleware(LoggingMiddleware())
pipeline.add_middleware(ValidationMiddleware(required_fields=["id", "name"]))

result = await pipeline.process(data)
```

#### 4. æ’ä»¶ç³»ç»Ÿ
```python
from src.financial_data_collector.core.plugins import PluginRegistry, SentimentAnalysisPlugin

registry = PluginRegistry()
registry.register_plugin("sentiment", SentimentAnalysisPlugin)

plugin = registry.create_plugin_instance("sentiment")
plugin.initialize({"sensitivity_threshold": 0.1})
result = plugin.execute("This is positive financial news")
```

#### 5. æ¨¡å—ç®¡ç†
```python
from src.financial_data_collector.core.module_manager import ModuleManager, ModuleConfig

module_manager = ModuleManager(di_container, event_bus)

# æ³¨å†Œæ¨¡å—
config = ModuleConfig(
    name="data_collector",
    dependencies=["config_manager"],
    startup_order=1
)
module_manager.register_module("data_collector", WebCrawler, config)

# å¯åŠ¨æ‰€æœ‰æ¨¡å—
await module_manager.start_all_modules()
```

## å®‰è£…å’Œé…ç½®

### ç¯å¢ƒè¦æ±‚
- Python 3.8+ (æœ¬åœ°å¼€å‘)
- Docker & Docker Compose (æ¨è)
- pip æˆ– conda

### ğŸ³ Docker å®‰è£… (æ¨è)

#### å¿«é€Ÿå¼€å§‹
```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd financial_data_collection

# è¿è¡Œåˆå§‹è®¾ç½®
make setup

# å¯åŠ¨å¼€å‘ç¯å¢ƒ
make dev

# æˆ–ä½¿ç”¨è„šæœ¬
./scripts/docker-setup.sh
```

#### ä½¿ç”¨ Docker Compose
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# å¯åŠ¨å¼€å‘ç¯å¢ƒ
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

#### æœåŠ¡è®¿é—®åœ°å€
- **åº”ç”¨**: http://localhost:8000
- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **pgAdmin**: http://localhost:5050 (admin@fdc.local/admin)
- **Redis Commander**: http://localhost:8081
- **Jupyter**: http://localhost:8888 (token: dev_token_123)

### ğŸ•·ï¸ Crawl4AI é›†æˆ

#### å®‰è£…Crawl4AI
```bash
# å®‰è£…Crawl4AI
make install-crawl4ai

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install crawl4ai==0.3.70
python -m crawl4ai.setup
```

#### ä½¿ç”¨Crawl4AI
```python
from financial_data_collector.core.crawler.web_crawler import WebCrawler

# åˆ›å»ºçˆ¬è™«
crawler = WebCrawler()
crawler.initialize({
    "extraction_strategy": "llm",
    "llm_config": {
        "provider": "openai",
        "model": "gpt-4",
        "api_token": "your-api-key"
    }
})

# çˆ¬å–é‡‘èæ•°æ®
result = await crawler.crawl_url(
    "https://finance.yahoo.com/quote/AAPL",
    {"extraction_strategy": "llm", "wait_for": 3}
)
```

#### æµ‹è¯•Crawl4AI
```bash
# è¿è¡Œæ¼”ç¤º
make test-crawl4ai

# æˆ–ç›´æ¥è¿è¡Œ
python examples/crawl4ai_demo.py
```

### ğŸ æœ¬åœ°å®‰è£…

#### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

#### é…ç½®æ–‡ä»¶
ç³»ç»Ÿä½¿ç”¨YAMLé…ç½®æ–‡ä»¶ï¼Œé»˜è®¤é…ç½®æ–‡ä»¶ä¸º `config.yaml`ï¼š

```yaml
# åº”ç”¨è®¾ç½®
app:
  name: "Financial Data Collector"
  version: "1.0.0"
  debug: false

# æ¨¡å—é…ç½®
modules:
  web_crawler:
    class: "src.financial_data_collector.core.crawler.web_crawler.WebCrawler"
    enabled: true
    dependencies: ["config_manager"]
    config:
      user_agent: "Financial Data Collector 1.0"
      request_delay: 1.0
```

## ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨åº”ç”¨
```bash
python -m src.financial_data_collector.main
```

### ç¼–ç¨‹æ¥å£
```python
from src.financial_data_collector.main import FinancialDataCollectorApp

app = FinancialDataCollectorApp()
await app.initialize(config)
await app.start()
```

### APIæ¥å£
ç³»ç»Ÿæä¾›RESTful APIæ¥å£ï¼š

- `GET /api/v1/status` - è·å–ç³»ç»ŸçŠ¶æ€
- `GET /api/v1/modules` - è·å–æ¨¡å—åˆ—è¡¨
- `POST /api/v1/tasks` - åˆ›å»ºä»»åŠ¡
- `GET /api/v1/health` - å¥åº·æ£€æŸ¥

## å¼€å‘æŒ‡å—

### åˆ›å»ºè‡ªå®šä¹‰æ¨¡å—
```python
from src.financial_data_collector.core.interfaces import BaseModule

class CustomDataProcessor(BaseModule):
    async def process_data(self, data):
        # è‡ªå®šä¹‰å¤„ç†é€»è¾‘
        return processed_data
    
    async def health_check(self):
        return {"status": "healthy"}
```

### åˆ›å»ºè‡ªå®šä¹‰æ’ä»¶
```python
from src.financial_data_collector.core.plugins.base import DataProcessorPlugin

class CustomPlugin(DataProcessorPlugin):
    def process_data(self, data):
        # è‡ªå®šä¹‰å¤„ç†é€»è¾‘
        return result
```

### åˆ›å»ºè‡ªå®šä¹‰ä¸­é—´ä»¶
```python
from src.financial_data_collector.core.middleware.base import Middleware

class CustomMiddleware(Middleware):
    async def process(self, data, next_middleware):
        # å¤„ç†å‰é€»è¾‘
        result = await next_middleware()
        # å¤„ç†åé€»è¾‘
        return result
```

## æµ‹è¯•

### è¿è¡Œæµ‹è¯•
```bash
pytest tests/ -v
```

### é›†æˆæµ‹è¯•
```bash
pytest tests/test_modular_system.py -v
```

## ç›‘æ§å’Œè¿ç»´

### å¥åº·æ£€æŸ¥
ç³»ç»Ÿæä¾›å¤šç§å¥åº·æ£€æŸ¥æ–¹å¼ï¼š

1. **æ¨¡å—çº§å¥åº·æ£€æŸ¥**: æ¯ä¸ªæ¨¡å—å®ç°è‡ªå·±çš„å¥åº·æ£€æŸ¥é€»è¾‘
2. **ç³»ç»Ÿçº§å¥åº·æ£€æŸ¥**: æ•´ä½“ç³»ç»ŸçŠ¶æ€ç›‘æ§
3. **APIå¥åº·æ£€æŸ¥**: HTTPæ¥å£å¥åº·æ£€æŸ¥

### æ—¥å¿—ç›‘æ§
ç³»ç»Ÿä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—ï¼Œæ”¯æŒå¤šç§æ—¥å¿—çº§åˆ«ï¼š
- DEBUG: è¯¦ç»†è°ƒè¯•ä¿¡æ¯
- INFO: ä¸€èˆ¬ä¿¡æ¯
- WARNING: è­¦å‘Šä¿¡æ¯
- ERROR: é”™è¯¯ä¿¡æ¯
- CRITICAL: ä¸¥é‡é”™è¯¯

### æ€§èƒ½ç›‘æ§
- å†…å­˜ä½¿ç”¨ç›‘æ§
- CPUä½¿ç”¨ç›‘æ§
- ç½‘ç»œI/Oç›‘æ§
- æ•°æ®åº“è¿æ¥ç›‘æ§

## æ‰©å±•æ€§

### æ·»åŠ æ–°çš„æ•°æ®æº
1. å®ç° `DataCollectorInterface` æ¥å£
2. æ³¨å†Œåˆ°ä¾èµ–æ³¨å…¥å®¹å™¨
3. é…ç½®æ¨¡å—å¯åŠ¨å‚æ•°

### æ·»åŠ æ–°çš„æ•°æ®å¤„ç†
1. å®ç° `DataProcessorInterface` æ¥å£
2. é…ç½®ä¸­é—´ä»¶ç®¡é“
3. è®¾ç½®å¤„ç†è§„åˆ™

### æ·»åŠ æ–°çš„å­˜å‚¨åç«¯
1. å®ç° `StorageInterface` æ¥å£
2. é…ç½®è¿æ¥å‚æ•°
3. æ³¨å†Œåˆ°æ¨¡å—ç®¡ç†å™¨

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å—å¯åŠ¨å¤±è´¥**
   - æ£€æŸ¥ä¾èµ–å…³ç³»
   - éªŒè¯é…ç½®å‚æ•°
   - æŸ¥çœ‹æ—¥å¿—ä¿¡æ¯

2. **æ•°æ®é‡‡é›†å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - éªŒè¯æ•°æ®æºé…ç½®
   - æŸ¥çœ‹é”™è¯¯æ—¥å¿—

3. **æ€§èƒ½é—®é¢˜**
   - è°ƒæ•´å¹¶å‘å‚æ•°
   - ä¼˜åŒ–æ•°æ®å¤„ç†é€»è¾‘
   - ç›‘æ§èµ„æºä½¿ç”¨

### è°ƒè¯•æ¨¡å¼
å¯ç”¨è°ƒè¯•æ¨¡å¼è·å–è¯¦ç»†æ—¥å¿—ï¼š
```yaml
app:
  debug: true
  log_level: "DEBUG"
```

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. åˆ›å»º Pull Request

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µ: [GitHub Repository]
- é—®é¢˜åé¦ˆ: [GitHub Issues]
- æ–‡æ¡£: [Documentation]
