
services:
  # Development application
  financial-data-collector-dev:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        USER_ID: ${USER_ID:-1000}
        GROUP_ID: ${GROUP_ID:-1000}
      target: development
    container_name: fdc-dev-app
    restart: unless-stopped
    ports:
      - "8002:8000"
    environment:
      - CONFIG_FILE=/app/config/development.yaml
      - CONFIG_ENV=development
      - DATABASE_URL=postgresql://fdc_user:fdc_password@postgres:5432/fdc_db
      - REDIS_URL=redis://redis:6379/0
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - PYTHONPATH=/app
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_DATABASE=financial_data
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
    volumes:
        - data_volume:/app/data
        - ./logs:/app/logs
        - ./config/app:/app/config
        - ./entrypoint.sh:/app/entrypoint.sh
        - data_volume:/app/data
    user: "root:root"  # 临时使用root用户测试权限问题
    depends_on:
      postgres:
        condition: service_started
      redis:
        condition: service_started
      clickhouse:
        condition: service_healthy

    networks:
      - fdc-dev-network
    #command: ["sleep", "infinity"]
    command: ["python", "-m", "src.financial_data_collector.main", "--debug"]

  # ClickHouse for financial data
  clickhouse:
    build:
      context: .
      dockerfile: Dockerfile.clickhouse
    container_name: fdc-clickhouse
    restart: unless-stopped
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      - CLICKHOUSE_INIT_DEBUG=1
      - CLICKHOUSE_SHARDS=1
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=""
    volumes:
      - ./data/clickhouse:/var/lib/clickhouse
      - ./logs/clickhouse:/var/log/clickhouse-server
      - ./config/clickhouse/clickhouse-server.xml:/etc/clickhouse-server/config.d/clickhouse-server.xml
      - ./config/clickhouse/users.xml:/etc/clickhouse-server/users.d/users.xml
      - ./scripts/clickhouse/init-clickhouse.sql:/docker-entrypoint-initdb.d/init-clickhouse.sql:ro
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 15s
      timeout: 10s
      retries: 10
    networks:
      - fdc-dev-network


  # Tabix Web UI for ClickHouse
  tabix:
    image: spoonest/clickhouse-tabix-web-client:latest
    container_name: fdc-tabix
    restart: unless-stopped
    ports:
      - "8082:80"
    depends_on:
      - clickhouse
    networks:
      - fdc-dev-network
    command: ["nginx", "-g", "daemon off;"]

  # PostgreSQL for development
  postgres:
    image: postgres:15-alpine
    container_name: fdc-dev-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=fdc_db
      - POSTGRES_USER=fdc_user
      - POSTGRES_PASSWORD=fdc_password
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    ports:
      - "5432:5432"
    networks:
      - fdc-dev-network

  # Redis for development
  redis:
    image: redis:7-alpine
    container_name: fdc-dev-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_dev_data:/data
    ports:
      - "6379:6379"
    networks:
      - fdc-dev-network

  # Jupyter notebook for data analysis
  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: fdc-jupyter
    restart: unless-stopped
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=dev_token_123
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
    networks:
      - fdc-dev-network

  fdc-pgadmin:
    image: dpage/pgadmin4
    container_name: fdc-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: hansong1983@gmail.com
      PGADMIN_DEFAULT_PASSWORD: yourpassword  # 替换成你想要的密码
    ports:
      - "8080:80"
    restart: always


  # Celery Worker for task processing
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        USER_ID: 1000
        GROUP_ID: 1000
    container_name: fdc-celery-worker
    restart: unless-stopped
    environment:
      - CONFIG_FILE=/app/config/development.yaml
      - DATABASE_URL=postgresql://fdc_user:fdc_password@postgres:5432/fdc_db
      - REDIS_URL=redis://redis:6379/0
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - PYTHONPATH=/app/src:/app
      - CELERY_MONITORING_ENABLED=true
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_DATABASE=financial_data
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
    volumes:
      - ./config/app:/app/config
    depends_on:
      - postgres
      - redis
    networks:
      - fdc-dev-network
    user: "root"
    command: ["celery", "-A", "financial_data_collector.core.tasks.celery_app", "worker", "--loglevel=info", "--concurrency=2"]
    healthcheck:
      test: ["CMD", "celery", "-A", "financial_data_collector.core.tasks.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery Beat for scheduled tasks
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    container_name: fdc-celery-beat
    restart: unless-stopped
    environment:
      - CONFIG_FILE=/app/config/development.yaml
      - DATABASE_URL=postgresql://fdc_user:fdc_password@postgres:5432/fdc_db
      - REDIS_URL=redis://redis:6379/0
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - PYTHONPATH=/app/src:/app
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config/app:/app/config
    depends_on:
      - postgres
      - redis
    networks:
      - fdc-dev-network
    command: ["celery", "-A", "financial_data_collector.core.tasks.celery_app", "beat", "--loglevel=info"]
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep 'celery -A financial_data_collector.core.tasks.celery_app beat' | grep -v grep || exit 1"]
      interval: 45s
      timeout: 15s
      retries: 3
    user: "root"

  # Redis Commander for Redis management
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: fdc-redis-commander
    restart: unless-stopped
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis
    networks:
      - fdc-dev-network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.11
    container_name: fdc-zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_SYNC_LIMIT=5             # 防止心跳超时引起 session 丢失
      - ZOOKEEPER_INIT_LIMIT=10            # 启动初始化更稳健
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log   # 分开数据与日志目录，防止磁盘写满
    networks:
      - fdc-dev-network

  kafka:
    image: confluentinc/cp-kafka:7.5.11
    container_name: fdc-kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_LOG_RETENTION_MS=604800000       # 7天数据保留
      - KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS=300000  # 每5分钟检查清理
      - KAFKA_LOG_CLEANER_ENABLE=true          # 启用日志压缩，减少空间浪费
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false  # 禁止自动创建 topic，防止误触发
      - KAFKA_NUM_NETWORK_THREADS=3            # 提高网络稳定性
      - KAFKA_NUM_IO_THREADS=8                 # 提高 I/O 并发能力
      - KAFKA_NUM_REPLICA_FETCHERS=2           # 稳定副本拉取机制（即使单节点也安全）
      - KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false  # 防止非干净选举（避免数据丢失）
      - KAFKA_DELETE_TOPIC_ENABLE=true         # 允许删除 topic，方便测试
      - KAFKA_MIN_INSYNC_REPLICAS=1
      - KAFKA_MAX_REQUEST_SIZE=10485760        # 10MB 消息大小上限
    volumes:
      - kafka_data:/var/lib/kafka/data
      - kafka_logs:/var/lib/kafka/logs
    depends_on:
      - zookeeper
    networks:
      - fdc-dev-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --list --bootstrap-server localhost:9092 > /dev/null 2>&1"]
      interval: 30s
      timeout: 15s
      retries: 10



  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: fdc-prometheus
    restart: unless-stopped
    ports:
      - "9091:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - fdc-dev-network
    command: --config.file=/etc/prometheus/prometheus.yml

volumes:
  postgres_dev_data:
    driver: local
  redis_dev_data:
    driver: local
  pgadmin_data:
    driver: local
  clickhouse_data:
    driver: local
  data_volume:
    driver: local
  prometheus_data: {}
  zookeeper_data: {}
  zookeeper_log: {}
  kafka_data: {}
  kafka_logs: {}

networks:
  fdc-dev-network:
    driver: bridge
    name: fdc-dev-network
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.name: "br-fdc-dev"

